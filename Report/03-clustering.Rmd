# Clustering

## Operazioni preliminari

Cominciamo caricando le librerie necessarie ed importando il grafo:
```{r echo=TRUE, message=FALSE, warning=FALSE}
# source a set of functions
source("util.R")

# import libraries
libraries_list <- c("ggraph", "igraph", "dplyr", "readr", "DiagrammeR", "tidyverse",
                    "Cairo", "networkD3", "CINNA", "scales", "gridExtra", "leiden",
                    "pander", "MCL", "caret")
import_libraries(libraries_list)

# import graph
edges <- read.csv(
  "../dataset/diseasome [Edges].csv",
  head = TRUE
)

nodes <- read.csv(
  "../dataset/diseasome [Nodes].csv",
  head = TRUE
)

nodes <- nodes %>% select(-timeset)
edges <- edges %>% select(-timeset, -label)

graph <- graph.data.frame(edges, directed = FALSE, vertices = nodes)
```

Il grafo caricato ha tutti i pesi degli archi uguali ad uno; li aggiorniamo calcolando per ogni coppia di nodi il numero di
geni che condividono:
```{r}
# for (i in 1:length(edges[, 5]))
# {
#   edge <- edges[i, ]
# 
#   n1 <- V(graph)[as.character(edge$Source)]
#   n2 <- V(graph)[as.character(edge$Target)]
# 
#   n1.neigh <- neighborhood(graph, nodes = n1)[[1]]
#   n2.neigh <- neighborhood(graph, nodes = n2)[[1]]
# 
#   n1.neigh <- as.numeric(n1.neigh[n1.neigh$X1 == "gene"])
#   n2.neigh <- as.numeric(n2.neigh[n2.neigh$X1 == "gene"])
# 
#   weight <- length(intersect(n1.neigh, n2.neigh))
# 
#   edges[i, ]$weight <- weight
# }

weight <- readRDS("edgeweights.rds")
edges$weight <- weight
```

Dato che il peso degli archi denota il numero di geni condivisi è possibile rimuovere tutti i nodi genici dal grafo in quanto
non portano più informazione utile, e sono inutili al fine del clustering. \newline
Siccome ogni coppia di nodi è connessa da un doppio arco identico, abbiamo deciso di disorientare il grafo mantenendo solamente uno dei due archi.
```{r}
graph <- graph.data.frame(edges, directed = FALSE, vertices = nodes)

UD_nogenes <- induced_subgraph(graph, which(nodes$X1 != "gene"))

# Rimuovo i doppi nodi
UD_nogenes <- igraph::simplify(UD_nogenes)
```

\newpage

## Groundtruth

Le malattie nel grafo sono clusterizzate in macrogruppi medici (cancro, cardiovascolare, etc...), verifichiamo se questi cluster si trovano
effettivamente vicini all'interno della rete
```{r Human Disease Network Clusters}
disease_clusters <- unique(V(UD_nogenes)$X1)

i = 1
for (disease in disease_clusters)
{
  V(UD_nogenes)[V(UD_nogenes)$X1 == disease]$color = i
  i = i + 1
}

plot_pretty_graph_legend(UD_nogenes, "graphopt", nodes$X1[nodes$X0 == "disease"], 
                         E(UD_nogenes)$weight, "Human Disease Network Clusters")
```

Dal grafo risultante vediamo un buon numero di nodi vicini tra di loro che condividono il tipo di malattia.\newline
Vediamo però anche un gran numero di nodi che sono lontani dal cluster di appartenenza!
```{r message=FALSE, warning=FALSE, include=FALSE}
graphs <- NULL
plots <- NULL
i <- 1

for (disease in disease_clusters)
{
  if (disease == "gene")
    next
    
  graphs[[i]] <- induced.subgraph(UD_nogenes, which(V(UD_nogenes)$X1 == disease))
  
  if (disease %in% c("Unclassified", "Respiratory"))
  {
    plots[[i]] <- ggraph(graphs[[i]], layout = "kk") +
      geom_node_point(colour = "red") +
      theme_graph(base_family = "sans", base_size = 11) +
      ggtitle(disease)
  } else
  {
    plots[[i]] <- ggraph(graphs[[i]], layout = "kk") +
      geom_edge_fan(colour = "gray", show.legend = TRUE) +
      geom_node_point(colour = "red") +
      theme_graph(base_family = "sans", base_size = 11) +
      ggtitle(disease)
  }
  i = i + 1
}
```

Proviamo a plottare le componenti connesse che condividono la stessa malattia:

```{r componente1, echo=FALSE, fig.height=4.6, fig.width=4.6}
grid.arrange(grobs = plots[1:4])
```

```{r componente2, echo=FALSE, fig.height=4.6, fig.width=4.6}
grid.arrange(grobs = plots[5:8])
```

```{r componente3, echo=FALSE, fig.height=4.6, fig.width=4.6}
grid.arrange(grobs = plots[9:12])
```

```{r componente4, echo=FALSE, fig.height=4.6, fig.width=4.6}
grid.arrange(grobs = plots[13:16])
```

```{r componente5, echo=FALSE, fig.height=4.6, fig.width=4.6}
grid.arrange(grobs = plots[17:20])
```

```{r componente6, echo=FALSE, fig.height=4.6, fig.width=4.6}
grid.arrange(grobs = plots[21:22])
```

Notiamo subito che non tutte le malattie formano un cluster compatto all'interno della rete, questo potrebbe essere molto problematico in quanto, non avendo attributi sui nodi, possiamo solo limitarci a raggruppare nodi che sono vicini all'interno della rete. \newline

Vediamo quante componenti connesse abbiamo per ogni cluster:
```{r}
n.cluster <- 0
n.cluster.single <- 0

clusters <- list()
cont.cluster <- 1

for (g in graphs)
{
  component <- components(g)
  n.cluster = n.cluster + length(component$csize[component$csize > 0])
  n.cluster.single = n.cluster.single + length(component$csize[component$csize == 1])
  
  for (i in 1:length(component$csize))
  {
    comp <- component$membership[component$membership == i]
    cont.cluster = cont.cluster + 1
  }
}
print(n.cluster)
print(n.cluster.single)
```
L'algoritmo ottimale dovrebbe essere in grado di distinguere 225 cluster basandosi unicamente sulla locazione del nodo all'interno della rete. \newline 
In particolare abbiamo 161 nodi i cui vicini non rappresentano la stessa malattia!

## Algoritmi di clustering

Gli algoritmi utilizzati si basano principalmente sul concetto di community detection e graph partitioning, non avendo a disposizione attributi sui nodi è praticamente impossibile pensare di operare con algoritmi di clustering tradizionali. \newline
Iniziamo costruendo una matrice utile per confrontare il cluster originale di ogni nodo con quello assegnatogli da uno degli algoritmi utilizzati:
```{r}
nodes_results <- nodes %>% filter(X1 != "gene") %>% select(-X0)
nodes_results$Betweenness <- NA
nodes_results$Fastgreedy <- NA
nodes_results$Louvain <- NA
nodes_results$Spinglass <- NA
nodes_results$Markov <- NA
nodes_results$Leiden <- NA
nodes_results$Label_prop <- NA
nodes_results$Label_prop_init <- NA
```

### Regola di clustering

Ogni cluster viene etichettato utilizzando la label più frequente al suo interno:
```{r}
label_cluster <- function(clusters)
{
  cluster_df <-
    as.data.frame(matrix(
      1:length(clusters),
      nrow = length(clusters),
      dimnames = list(NULL, "id")
    ))
  
  for (c in 1:length(clusters))
  {
    labels <- V(UD_nogenes)[clusters[[c]]]$X1
    labels <- labels[labels != "Multiple"]
    
    if (length(labels) != 0)
    {
      value <- which.max(unlist(table(labels)))
      cluster_df$name[cluster_df$id == c] <- names(value)[1]
    } else
    {
      cluster_df$name[cluster_df$id == c] <- "Multiple"
    }
  }
  
  return(cluster_df)
}
```

\newpage

## Girvan–Newman

Il primo algoritmo di clustering che abbiamo utilizzato è basato sull'utilizzo della misura di edge betweenness. \newline
L'algoritmo di Girvan-Newman [-@girvan-newman] si basa sull'idea che gli archi che connettono moduli separati della rete 
dovrebbero avere un alto valore di edge betweennes. 

```{r Newman Clusters, message=FALSE, warning=FALSE}
betweennes.communities <- cluster_edge_betweenness(UD_nogenes, directed = FALSE, 
                                                   weights = E(UD_nogenes)$weight)

print(paste("N° di communities: ", max(betweennes.communities$membership)))

plot_pretty_graph(UD_nogenes, "graphopt", betweennes.communities$membership, E(UD_nogenes)$weight, 
                  "Girvan–Newman Clusters")
```
Questo algoritmo distingue 29 cluster all'interno della rete, ci aspettiamo quindi che i risultati in termini di accuratezza non siano particolarmente elevati in quanto non è ovviamente in grado di distinguere, ad esempio, i cluster di dimensione uno.

```{r include=FALSE}
betweennes_cluster_df <- label_cluster(betweennes.communities)
for (n in 1:length(betweennes.communities$membership))
{
  nodes_results$Betweenness[n] <- betweennes_cluster_df$name[betweennes.communities$membership[n]]
}
```

## Fastgreedy
L'algoritmo fastgreedy [-@fastgreedy] cerca le communities all'interno della rete andando a massimizzare il valore di modularità, utilizzando un approccio bottom-up, rispetto a quello top-down utilizzato da Girvan–Newman. \newline
Inizialmente ogni nodo rappresenta una community e, iterativamente, ogni nodo viene unito in modo tale che l'unione sia localmente ottima (massimo aumento della modularità). L'algoritmo si ferma quando non è più possibile far aumentare la modularità.

```{r Fastgreedy Clusters}
fgreedy.communities <- cluster_fast_greedy(UD_nogenes, modularity = TRUE,
                                           weights = E(UD_nogenes)$weight)

print(paste("N° di communities: ", max(fgreedy.communities$membership)))

plot_pretty_graph(UD_nogenes, "graphopt", fgreedy.communities$membership, 
                  E(UD_nogenes)$weight, "Fastgreedy Clusters")
```
Notiamo che il risultato è simile a quello prodotto da Girvan–Newman, ma il numero di cluster è ancora minore e quindi molto probabilmente anche le performance saranno più basse.

```{r include=FALSE}
fgreedy_cluster_df <- label_cluster(fgreedy.communities)
for (n in 1:length(fgreedy.communities$membership))
{
  nodes_results$Fastgreedy[n] <- fgreedy_cluster_df$name[fgreedy.communities$membership[n]]
}
```

## Louvain
L'algoritmo denominato Louvain [-@louvain] possiamo vederlo come una evoluzione del precedente. \newline
Anche in questo caso l'obiettivo è quello di massimizzare la modularità, vengono seguiti gli stessi step dell'algoritmo precedente, dopo di che viene creato un grafo i cui nodi sono le community create e si ripete il procedimento fino a quando non è più possibile far aumentare la modularità:

```{r Louvain Clusters}
louvain.communities <- cluster_louvain(UD_nogenes, weights = E(UD_nogenes)$weight)

print(paste("N° di communities: ", max(louvain.communities$membership)))

plot_pretty_graph(UD_nogenes, "graphopt", louvain.communities$membership, 
                  E(UD_nogenes)$weight, "Louvain Clusters")
```

Anche in questo caso non ci aspettiamo che le performance differiscano particolarmente dagli algoritmi precedenti.

```{r include=FALSE}
louvain_cluster_df <- label_cluster(louvain.communities)
for (n in 1:length(louvain.communities$membership))
{
  nodes_results$Louvain[n] <- louvain_cluster_df$name[louvain.communities$membership[n]]
}
```

## Spinglass

Questo algoritmo [-@spinglass] fa utilizzo di tecniche derivate dalla statistica fisica per costruire le community. 
Permette di specificare il parametro spins che idealmente rappresenta il numero k di cluster, il problema è che l'algoritmo cerca di riempire tutti i 225 cluster, ma è possibile che non ci riesca e quindi il risultato mostrerà un numero di cluster molto ridotto:
```{r Spinglass Clusters}
spinglass.communities <- cluster_spinglass(UD_nogenes, spins = 225, 
                                           weights = E(UD_nogenes)$weight)

print(paste("N° di communities: ", max(spinglass.communities$membership)))

plot_pretty_graph(UD_nogenes, "graphopt", spinglass.communities$membership, 
                  E(UD_nogenes)$weight, "Spinglass Clusters")
```

Dei 225 spin iniziali, solamente 41 sono stati popolati. L'algoritmo rileva comunque più cluster dei precedenti e dovrebbe quindi migliorare le prestazioni.

```{r include=FALSE}
spinglass_cluster_df <- label_cluster(spinglass.communities)
for (n in 1:length(spinglass.communities$membership))
{
  nodes_results$Spinglass[n] <- spinglass_cluster_df$name[spinglass.communities$membership[n]]
}
```

## Markov Cluster Algorithm

L'algoritmo MCL [-@mcl] si basa sulla simulazione di percorsi stocastici sul grafo, sfruttando il paradigma di clustering secondo il quale le community hanno la seguente proprietà: \newline
"Un cammino randomico su un grafo G che visita un cluster denso molto probabilmente uscirà dal cluster solamente dopo aver attraversato buona parte dei suoi vertici".
Il parametro inflation permette di aumentare la granularità, questo fa in modo di permettere all'algoritmo di rilevare cluster più piccoli e quindi aumentare il numero di cluster rilevati dall'algoritmo.
```{r Markov Clusters, message=FALSE, warning=FALSE}
adjmat <- as_adj(UD_nogenes, type = "both", attr = "weight")
mcl.communities <- mcl(adjmat, addLoops = FALSE, inflation = 4, allow1 = TRUE) 

print(paste("N° di communities: ", mcl.communities$K))

plot_pretty_graph(UD_nogenes, "graphopt", mcl.communities$Cluster, E(UD_nogenes)$weight, 
                  "Markov Clusters")
```

L'algoritmo rileva ben 169 communities, l'accuratezza ci dimostrerà se sono sensate, oppure i raggruppamenti sono molto randomici.

Esempio di sottografo con label cancer
```{r Cancer MCL subgraph, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
mcl_cancer_subgraph <- induced_subgraph(UD_nogenes, V(UD_nogenes)[mcl.communities$Cluster == 3])

ggraph(mcl_cancer_subgraph, layout="graphopt") +
  geom_edge_fan(aes(width=E(mcl_cancer_subgraph)$weight), colour = "gray66", show.legend = FALSE) +
  geom_node_point(aes(fill="#8DD3C7"), shape=21, col="grey25", show.legend = FALSE) +
  scale_edge_width_continuous(range=c(0.2,0.9)) +
  scale_size_continuous(range=c(1, 10)) +
  theme_graph(base_size = 11, base_family = "sans") +
  ggtitle("Cancer MCL subgraph") 
```

```{r include=FALSE}
markov_cluster_df <- as.data.frame(matrix(1:(mcl.communities$K), nrow = mcl.communities$K, 
                                          dimnames = list(NULL, "id")))
markov_cluster_df$name <- NA
markov_cluster_df$id <- unique(mcl.communities$Cluster)
for (id in markov_cluster_df$id)
{
    labels <- V(UD_nogenes)[mcl.communities$Cluster == id]$X1
    labels <- labels[labels != "Multiple"]
    
    value <- which.max(unlist(table(labels)))
    
    if (length(value) != 0)
    {
      markov_cluster_df$name[markov_cluster_df$id == id] <- names(value)[1]
    }
    else
    {
      markov_cluster_df$name[markov_cluster_df$id == id] <- "Multiple"
    }
}
  
for (n in 1:length(mcl.communities$Cluster))
{
  nodes_results$Markov[n] <- markov_cluster_df$name[mcl.communities$Cluster[n] == markov_cluster_df$id]
}
```

## Leiden Algorithm

L'algoritmo Leiden [-@leiden] è un ulteriore evoluzione dell'algoritmo Louvain mostrato in precedenza. I creatori dell'algoritmo hanno dimostrato come Louvain generi spesso delle community che non sono ottimali, inoltre questo algoritmo converge ad una soluzione ottima molto più rapidamente. \newline
In particolare con questo algoritmo è possibile decidere a priori il numero di cluster e per questo motivo dovrebbe essere in grado di ottenere performance molto buone sul grafo in questione.

```{r Leiden Clusters}
adjmat <- as_adj(UD_nogenes, type = "both", attr = "weight")
leiden.communities <- leiden(adjmat, resolution_parameter = 86)
print(max(leiden.communities))
leiden.communities <- make_clusters(UD_nogenes, membership = leiden.communities)

plot_pretty_graph(UD_nogenes, "graphopt", leiden.communities$membership, 
                  E(UD_nogenes)$weight, "Leiden Clusters")
```

Settando il parametro di resolution è possibile far generare un numero di cluster pari al numero di componenti connesse distinte per malattia nel nostro grafo.

```{r include=FALSE}
leiden_cluster_df <- label_cluster(leiden.communities)
for (n in 1:length(leiden.communities$membership))
{
  nodes_results$Leiden[n] <- leiden_cluster_df$name[leiden.communities$membership[n]]
}
```

## Label propagation

L'algoritmo di label propagation [-@labelprop] inizializza tutti i nodi con una label random e poi iterativamente aggiorna la label di ogni nodo basandosi su una votazione a maggioranza tra le label dei vicini.
Il risultato dell'algoritmo dipende dall'inizializzazione, settiamo quindi il seed per permettere la riproducibilità.

```{r Label Propagation Clusters}
set.seed(09062019)

label_prop.communities <- cluster_label_prop(UD_nogenes, weights = E(UD_nogenes)$weight)

print(paste("N° di communities: ", max(label_prop.communities$membership)))

plot_pretty_graph(UD_nogenes, "graphopt", label_prop.communities$membership, 
                  E(UD_nogenes)$weight, "Label Propagation Clusters")
```
L'algoritmo è molto semplice ed estremamente rapido, inoltre rileva ben 62 community che potrebbero essere indice di performance migliori.

```{r include=FALSE}
label_prop_cluster_df <- label_cluster(label_prop.communities)
for (n in 1:length(label_prop.communities$membership))
{
  nodes_results$Label_prop[n] <- label_prop_cluster_df$name[label_prop.communities$membership[n]]
}
```

Viene poi testato l'algoritmo utilizzando una tecnica semi-supervised, inizializzando circa il 20% delle label e vedendo come si comporta.

```{r Label Propagation init Clusters}
set.seed(09062019)
V(UD_nogenes)$initial <- NA
V(UD_nogenes)$fixed <- NA

for (dis in disease_clusters)
{
  disnodes <- V(UD_nogenes)[V(UD_nogenes)$X1 == dis]
  disnodes <- sample(disnodes, 0.25 * length(disnodes))
  for (node in disnodes)
  {
      V(UD_nogenes)[node]$initial <- which(disease_clusters == V(UD_nogenes)[node]$X1)
      V(UD_nogenes)[node]$fixed <- TRUE
  }
}

V(UD_nogenes)$initial[is.na(V(UD_nogenes)$initial)] <- -1
V(UD_nogenes)$fixed[is.na(V(UD_nogenes)$fixed)] <- FALSE
print(paste("Percentuale vertici inizializzati", 
            sum(V(UD_nogenes)$initial > 0) / length(V(UD_nogenes))))

label_prop_init.communities <- cluster_label_prop(UD_nogenes,
                                                  weights = E(UD_nogenes)$weight,
                                                  initial = V(UD_nogenes)$initial, 
                                                  fixed = V(UD_nogenes)$fixed)

print(paste("N° di communities: ", max(label_prop_init.communities$membership)))

plot_pretty_graph(UD_nogenes, "graphopt", label_prop_init.communities$membership, 
                  E(UD_nogenes)$weight, "Label Propagation init Clusters")
```

Il numero rilevate viene ridotto, potenzialmente le performance dovrebbero però migliorare in quanto l'algoritmo ha una migliore conoscenza della struttura del grafo.

```{r}
label_prop_init_cluster_df <- label_cluster(label_prop_init.communities)
for (n in 1:length(label_prop_init.communities$membership))
{
  nodes_results$Label_prop_init[n] <- 
    label_prop_init_cluster_df$name[label_prop_init.communities$membership[n]]
}
```

## Valutazione degli algoritmi

### Accuracy

Valutiamo gli algoritmi in termini di accuratezza di classificazione dei nodi.
Abbiamo deciso di considerare i nodi con etichetta "Multiple", che identificano nodi appartenenti a più cluster come dei "Jolly", facendo in modo che risultino sempre veri positivi.

```{r message=FALSE, warning=FALSE}
compute_confmat <- function(groundtruth, communities.algo)
{
  l.union <- union(groundtruth, communities.algo)
  
  groundtruth[groundtruth == "Multiple"] <- communities.algo[groundtruth == "Multiple"]
  
  atable <-
    table(
      factor(groundtruth, l.union),
      factor(communities.algo, l.union)
    )
  
  return(confusionMatrix(atable))
}

accuracy_df = data.frame(matrix(ncol = 23, nrow = 8))
colnames(accuracy_df) <- c(disease_clusters, "Accuracy")
rownames(accuracy_df) <- c("betweennes", "fastgreedy", "louvain", "spinglass", "markov",
                           "leiden", "label prop", "label prop init")

for (i in 4:length(nodes_results))
{
  confmat <- compute_confmat(nodes_results$X1, nodes_results[, i])
  accuracy_df[i - 3, ] <- unname(c(diag(confmat$table / rowSums(confmat$table)),
                                confmat$overall[1]))
}

accuracy_df$Multiple <- NULL

accuracy_df <- as.data.frame(t(accuracy_df))
colnames(accuracy_df) <- accuracy_df[1, ]
accuracy_df <- accuracy_df[-1, ]

colnames(accuracy_df) <- c("betweennes", "fastgreedy", "louvain", "spinglass", "markov",
                           "leiden", "label prop", "label prop init")

panderOptions('table.split.table', 'Inf')
pander(format(accuracy_df, digits = 3))
```

### Adjusted Rand index

L'adjusted Rand index (ARI) misura l'accuratezza dei raggruppamenti costruiti dagli algoritmi utilizzando la seguente formula applicata sulla tabella di contingenza dell'algoritmo:

$$ ARI = \frac{\sum_{ij}{n_{ij}\choose 2} - \Big[\sum_i{a_i\choose 2} \sum_i{b_j\choose 2} \Big]/{n\choose 2}}
              {\frac{1}{2} \Big[\sum_i{a_i\choose 2} + \sum_i{b_j\choose 2} \Big] 
              - \Big[\sum_i{a_i\choose 2} \sum_i{b_j\choose 2} \Big]/{n\choose 2}}  $$
            

Dove $a_i$ è la somma della riga i, $b_j$ è la somma della colonna j ed n è il numero totale di nodi nel grafo.

```{r message=FALSE, warning=FALSE}
ari_df <- data.frame(matrix(ncol = 1, nrow = 8))
colnames(ari_df) <- c("Adjusted Rand index")
rownames(ari_df) <- c("betweennes", "fastgreedy", "louvain", "spinglass", "markov",
                           "leiden", "label prop", "label prop init")

for (i in 1:8)
{
  ari_df[i, ] <- compute_ari(readRDS(paste(
    "contingency_matrices/",
    gsub(" ", "_", rownames(ari_df)[i]),
    ".rds",
    sep = ""
  )))
}
```

####  Distribuzione di centralità dell'intera rete delle malattie (nogenes)
```{r}
distribution = data.frame(matrix(ncol = 1, nrow = 4))
colnames(distribution) <- "Values"
rownames(distribution) <- c("Mean Degree Distribution", "Mean Betweenness Distribution", 
                           "Mean Closeness Distribution", "Mean Eigenvector Distribution")

distribution[1,1] <- mean(UD_nogenes_degree$res)
distribution[2,1] <- mean(UD_nogenes_betweenness)
distribution[3,1] <- mean(UD_nogenes_closeness)
distribution[4,1] <- mean(UD_nogenes_eigen$vector)

pander(format(distribution, digits = 3, justify="left"))
```

```{r}
print(paste("Media dei pesi di Human Disease Network: ", format(mean(E(UD_nogenes)$weight), digits=3)))
```

#### Distribuzione di centralità dei clusters reilevato con l'algoritmo Leiden

```{r}
l <- length(unique(leiden.communities$membership))

leiden_degree <- data.frame(matrix(ncol = 1, nrow = l))
leiden_betweenness <- data.frame(matrix(ncol = 1, nrow = l))
leiden_closeness <- data.frame(matrix(ncol = 1, nrow = l))
leiden_eigen <- data.frame(matrix(ncol = 1, nrow = l))

leiden_weights <- data.frame(matrix(ncol = 1, nrow = l))

colnames(leiden_degree) <- "Values"
colnames(leiden_betweenness) <- "Values"
colnames(leiden_closeness) <- "Values"
colnames(leiden_eigen) <- "Values"
colnames(leiden_weights) <- "Values"
  
for (i in unique(leiden.communities$membership)) {
  leiden_subgraph <- induced_subgraph(UD_nogenes, 
                                      which(leiden.communities$membership == i))
                                   
  leiden_degree_vect <- centr_degree(leiden_subgraph, mode = "all", 
                                          normalized = TRUE)
  
  leiden_betweenness_vect <- betweenness(leiden_subgraph, v = V(leiden_subgraph), 
                                           normalized = TRUE, 
                                           weights=E(leiden_subgraph)$weight)

  leiden_closeness_vect <- closeness(leiden_subgraph, v = V(leiden_subgraph), 
                                       normalized = TRUE, 
                                       weights=E(leiden_subgraph)$weight)
  
  leiden_eigen_vect <- eigen_centrality(leiden_subgraph,
                                         weights=E(leiden_subgraph)$weight)
  
  leiden_weights[i, 1] <- mean(E(leiden_subgraph)$weight)
    
  leiden_degree[i, ] <- mean(leiden_degree_vect$res)
  leiden_betweenness[i, ] <- mean(leiden_betweenness_vect)
  leiden_closeness[i, ]  <- mean(leiden_closeness_vect)
  leiden_eigen[i, ] <- mean(leiden_eigen_vect$vector)
}

leiden_weights$Values[is.na(leiden_weights$Values)] <- 0
leiden_degree$Values[is.na(leiden_degree$Values)] <- 0
leiden_betweenness$Values[is.na(leiden_betweenness$Values)] <- 0
leiden_closeness$Values[is.na(leiden_closeness$Values)] <- 0
leiden_eigen$Values[is.na(leiden_eigen$Values)] <- 0
```

```{r}
total_distribution = data.frame(matrix(ncol = 1, nrow = 4))
colnames(total_distribution) <- "Values"
rownames(total_distribution) <- c("Mean Degree Distribution", 
                                  "Mean BetweennessDistribution", 
                                  "Mean Closeness Distribution", 
                                  "Mean Eigenvector Distribution")

total_distribution[1,1] <- mean(leiden_degree[,1])
total_distribution[2,1] <- mean(leiden_betweenness[,1])
total_distribution[3,1] <- mean(leiden_closeness[,1])
total_distribution[4,1] <- mean(leiden_eigen[,1])

pander(format(total_distribution, digits = 3, justify="left"))
```

```{r}
print(paste("Media della media dei pesi di ogni cluster individuato con l'algoritmo Leiden: ", 
            format(mean(leiden_weights[,1]), digits=3)))
```

#### Analisi sulle malattie che venivano contrassegnate come Unclassified:
```{r}
unclassified_disease <- nodes_results %>% filter(X1 == "Unclassified")

unclassified_disease <- unclassified_disease %>% select(label, Betweenness, Fastgreedy,
                                                        Louvain,Spinglass, Markov, 
                                                        Leiden, Label_prop,
                                                        Label_prop_init)

panderOptions('table.split.table', 'Inf')
pander(format(unclassified_disease, digits=3))
```

- Bannayan-Riley-Ruvalcaba syndrome identificata da tutti e quattro gli algoritmi come cancer: 
da alcune risorse (https://omim.org/entry/158350?search=bannayan-riley-ruvalcaba%20syndrome&highlight=%22bannayan%20riley%20ruvalcaba%20syndrome%22%20%22bannayan%20riley%20ruvalcaba%20syndromic%22%20%22bannayan%20riley%20ruvalcaba%22%20%22bannayanrileyruvalcaba%20syndrome%22%20%22bannayanrileyruvalcaba%20syndromic%22%20bannayanrileyruvalcaba%20syndrome%20syndromic) pare ci sia un collegamento con il cancro al seno.

- Benzene toxicity susceptibility to : leukemia, post-chemotherapy, susceptibility to, included
breast cancer, post-chemotherapy poor survival in

- Aquaporin-1 deficiency classicifata in Hematological: 
collegamenti rilevati :Blood group, Colton


#### Analisi sulle malattie che venivano contrassegnate come Multiple:
```{r}
multiple_disease <- nodes_results %>% filter(X1 == "Multiple")
multiple_disease <- multiple_disease %>% select(label, Betweenness, Fastgreedy, Louvain, Spinglass, 
                                 Markov, Leiden, Label_prop, Label_prop_init)

panderOptions('table.split.table', 'Inf')
pander(format(multiple_disease, digits=3))
```

- Fanconi anemia is a clinically and genetically heterogeneous disorder that causes genomic instability. Characteristic clinical features include developmental abnormalities in major organ systems, early-onset bone marrow failure, and a high predisposition to cancer

- Dejerine-Sottas neuropathy is a demyelinating peripheral neuropathy with onset in infancy
